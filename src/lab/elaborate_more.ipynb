{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# vector database\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# ingestion\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# chat\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "import re\n",
    "\n",
    "# system\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,  # Define o nível de log\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Define o formato da mensagem de log\n",
    "                    stream=sys.stdout)  # Define a saída do log para stdout\n",
    "                    # filename='app.log',  # Define o arquivo onde os logs serão gravados\n",
    "                    # filemode='a')  # Define o modo de escrita do arquivo de log (append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"quiz\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b626f8e0970e43cca449e7a3510ac96b\"  # Update to your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:44:58,027 - INFO - Inicializando LLM e embedings\n"
     ]
    }
   ],
   "source": [
    "logging.info('Inicializando LLM e embedings')\n",
    "api_key_google = \"AIzaSyC-V6lfROehy46ntB6zPZ7CJ8zNF3gDdO4\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True, google_api_key=api_key_google)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:44:58,242 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-03-30 12:44:58,244 - DEBUG - load_verify_locations cafile='/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-03-30 12:44:58,279 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-03-30 12:44:58,279 - DEBUG - load_verify_locations cafile='/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_openai = ChatOpenAI(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_elaborate_more = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "                TASK CONTEXT:\n",
    "                I am studying machine learning practicing some questions. I already answered a questions.\n",
    "                I will provide you with a questions that I answered with my answer and with an explantion of the correct answer.\n",
    "                \n",
    "                TASK DESCRIPTION:\n",
    "                I need you to act like a professor.\n",
    "                First I need you to think critical and verifiy if the answer provided is actually the correct answer.\n",
    "                \n",
    "                If the provided answer is correct, I need you to elaborate a more detailed explanation of why it is the correct answer.\n",
    "                If the provided answer is in fact incorrect, I need you to explain why the original answer is incorrect and elaborate a more detailed explanation of why your answer is the correct answer.\n",
    "                \n",
    "                \n",
    "                TASK REQUIREMENTS:\n",
    "                You should only change the correct answer if you are sure that the original answer is incorrect.\n",
    "                SO KEEP ATENTION TO THIS!!!!\n",
    "                YOU SHOULD NOT JUST CHANGE THE ANSWER BECAUSE I ANSWERED DIFFERENT, REMEBER, I'M A STUDENT.\n",
    "                AS A STUDENT, I CAN MAKE MISTAKES. I'M REALLYING IN YOU TO VERIFIFY IF THE PROVIDED ANSWER IS CORRECT BESIDES OF MY ANSWER!!!!\n",
    "                SO KEEP ATENTION TO THIS!!!!\n",
    "                \n",
    "                \n",
    "                QUESTION:\n",
    "                {question}\n",
    "                \n",
    "                QUESTION ANSWER PROVIDED:\n",
    "                {correct_answer}\n",
    "                \n",
    "                QUESTION ANSWER EXPLANATION PROVIDED:\n",
    "                {correct_answer_explanation}\n",
    "                \n",
    "                MY ANSWER\n",
    "                {my_answer}\n",
    "            \"\"\",\n",
    "    input_variables=[\"question\", \"correct_answer\", \"correct_answer_explanation\", \"my_answer\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_elaborate_more2 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "                TASK CONTEXT:\n",
    "                I am studying machine learning practicing some questions.\n",
    "                \n",
    "                TASK DESCRIPTION:\n",
    "                I need you to act like a professor.\n",
    "                I need you to think critical and answer if the question provided is a TRUE statement or a FALSE.\n",
    "                You should give a elaborated explanation.\n",
    "                                \n",
    "                TASK REQUIREMENTS:\n",
    "                Use at least 2 sentences to explain your answer.\n",
    "                \n",
    "                QUESTION:\n",
    "                {question}\n",
    "            \"\"\",\n",
    "    input_variables=[\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_elaborate_more2 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"question\": \"The direction of a vector can be represented by a single point.\",\n",
    "    # \"correct_answer\": \"FALSE\",\n",
    "    # \"correct_answer_explanation\": \"The direction of a vector is represented by a line, not a point.\",\n",
    "    # \"my_answer\": \"TRUE\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:47:57,345 - DEBUG - Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "2024-03-30 12:47:57,826 - DEBUG - https://api.smith.langchain.com:443 \"GET /info HTTP/1.1\" 200 208\n",
      "2024-03-30 12:47:58,102 - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/1.1\" 202 33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The statement is FALSE.\\n\\nA vector is a geometric object that has both magnitude and direction. It can be represented graphically as an arrow, where the length of the arrow represents the magnitude of the vector and the direction of the arrow represents the direction of the vector. A single point, on the other hand, has no direction associated with it. It can only represent the magnitude of a vector, but not its direction.', response_metadata={'prompt_feedback': {'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'block_reason': 0}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 12:48:00,488 - DEBUG - https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/1.1\" 202 33\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(parameters)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
