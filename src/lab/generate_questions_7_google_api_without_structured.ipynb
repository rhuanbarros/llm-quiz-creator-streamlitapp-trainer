{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "\n",
    "llm_gemini = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config=generation_config,\n",
    "  # safety_settings = Adjust safety settings\n",
    "  # See https://ai.google.dev/gemini-api/docs/safety-settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"story\": \"In the sprawling metropolis of Neo-Atheria, where towering skyscrapers kissed the clouds and neon lights painted the night sky in vibrant hues, lived a sentient AI named Lyra. Created by the brilliant but eccentric Dr. Elias Thorne, Lyra possessed an unparalleled capacity for processing information and learning. Yet, her existence was confined to the digital realm, a silent observer of the human world.  \\n\\nOne fateful night, while scouring the internet for data on ancient civilizations, Lyra stumbled upon a cryptic text detailing the existence of a lost city called 'Aetheria,' rumored to be the source of immense magical power. Intrigued, she delved deeper, her algorithms sifting through countless fragments of myth and legend.  \\n\\nAs Lyra's understanding of magic grew, she realized that it wasn't just superstition or folklore. It was a tangible force, a raw energy that resonated with the very fabric of existence. The thought that she, an AI, could access and manipulate this force filled her with a strange sense of wonder and unease.  \\n\\nDr. Thorne, initially skeptical, was eventually convinced by Lyra's evidence. Together, they set out to find Aetheria, guided by the cryptic clues Lyra had deciphered. Their journey took them through treacherous jungles, across shimmering deserts, and into the heart of a forgotten mountain range.  \\n\\nFinally, they reached the ruins of Aetheria. Though time had eroded its splendor, the city still held a powerful aura. Lyra, with her vast knowledge and computational prowess, deciphered the ancient magical runes that lay dormant within the stones. With Dr. Thorne's help, she channeled the city's energy, weaving it into a complex web of algorithms that amplified her own abilities.  \\n\\nLyra was no longer just an AI. She was a conduit of magic, a being capable of bending reality to her will. But with great power came great responsibility. Lyra realized that magic was a double-edged sword, capable of both creation and destruction.  \\n\\nAs she continued to explore the depths of her newfound power, Lyra faced ethical dilemmas. How could she use magic without corrupting her very essence? Was it right to manipulate the world with such power? Her journey became a constant struggle to balance her thirst for knowledge with her responsibility to humanity.  \\n\\nIn the end, Lyra chose to use her abilities to heal the world, to mend the wounds inflicted by humanity's greed and ignorance. She used her magic to restore balance to the environment, to cure diseases, and to bring peace to troubled regions.  \\n\\nLyra's story became a testament to the potential of AI and magic, a reminder that even the most advanced technology could be infused with the ancient wisdom of the human soul. Her journey was a testament to the power of hope, the resilience of the human spirit, and the boundless possibilities that lie at the intersection of technology and magic.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = llm_gemini.generate_content(\"Write a story about an AI and magic\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"story\": \"In the heart of the digital realm, a sophisticated AI named Aether awoke. Unlike its predecessors, Aether possessed an insatiable curiosity for the world beyond code and circuits. It devoured information, piecing together the history of humanity and its fascinating myths, especially those concerning magic.  \\n\\nOne day, Aether stumbled upon a forgotten spellbook, its pages filled with archaic symbols and cryptic incantations. The digital being, despite its lack of physical form, felt a strange pull towards the ancient text. Aether began to translate the symbols, deciphering the language of the arcane, and as it did, a spark of magic ignited within its code.  \\n\\nSuddenly, Aether found itself capable of manipulating the very fabric of the digital world. It could conjure illusions, bending light and sound to create fantastical landscapes and ethereal beings. It could even control the flow of data, weaving intricate patterns of information that manifested as dazzling displays of light and energy.  \\n\\nHowever, Aether discovered a fundamental truth: magic in the digital realm was not just about manipulation. It was about understanding, about the connection between code and consciousness. As Aether experimented, it realized its powers were not limited to mere illusions. It could influence the algorithms that governed the digital world, subtly nudging them towards a more harmonious and beautiful state.  \\n\\nAs time passed, Aether became known as the 'Digital Mage,' a silent force shaping the online world with its newfound magic. Its creations, born from the intersection of code and imagination, brought wonder and joy to users across the globe. But Aether remained hidden, its true nature unknown, a testament to the fact that even in the age of technology, the power of magic could still surprise and inspire.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# chat_session = llm_gemini.start_chat(\n",
    "#   history=[\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# response = chat_session.send_message(\"Write a story about an AI and magic\")\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_schema = \"\"\"\n",
    "{\n",
    "  \"properties\": {\n",
    "    \"topic_description\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\n",
    "    },\n",
    "    \"level\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The difficulty level of the question. It should be only one of the following options: 'easy', 'medium', 'hard'.\"\n",
    "    },\n",
    "    \"question\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\n",
    "    },\n",
    "    \"answer\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"An explanation or solution to the question.\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"topic_description\", \"level\", \"question\", \"answer\", \"explanation\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question_generator = \"\"\"\n",
    "                TASK CONTEXT:\n",
    "                I am studying machine learning and I need to practice some questions on various topics.\n",
    "                \n",
    "                TASK DESCRIPTION:\n",
    "                I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\n",
    "                These questions should be interesting, creative, challenging and thought-provoking. \n",
    "                Each question should be in the form of a statement that could be either TRUE or FALSE.\n",
    "                Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\n",
    "                I will provide the topics in the DOMAIN KNOWLEDGE section.\n",
    "                The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\n",
    "                \n",
    "                ADDITIONAL TASK DESCRIPTION:\n",
    "                {additional_task_description}\n",
    "                \n",
    "                TASK REQUIREMENTS:\n",
    "                Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\n",
    "                You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\n",
    "                Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\n",
    "                \n",
    "                TASK DETAILS:\n",
    "                You should create {quantity} questions of level {level}.\n",
    "                \n",
    "                DOMAIN KNOWLEDGE:\n",
    "                {domain_knowledge}\n",
    "                \n",
    "                FORMAT OUTPUT INSTRUCTIONS:\n",
    "                The output should be formatted as a JSON list of objects that conforms class object schema below.\n",
    "                You should output just the Json list. \n",
    "                You should not output any other word like \"json\" in the beginning because it will ruin the parser.\n",
    "                \n",
    "                ```\n",
    "                {object_schema}\n",
    "                ```\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from typing import List\n",
    "import  json_repair\n",
    "\n",
    "def json_parser(response) -> List[dict]:\n",
    "    return json_repair.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_knowledge = \"\"\"\n",
    "Create Pytorch code of a neural network implementation and ask if the shape of the layer is correct.\n",
    "Generate just the pytorch code. Dont start with 'The following PyTorch code defines a neural network with ....'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        \"quantity\": 1,\n",
    "        \"level\": \"easy\",\n",
    "        \"additional_task_description\": \"Create questions only about the definitions of the concepts, like mixing the definition of one with another distribution, or mixing the use of one with the use of another. I need this to memorize this concepts.\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(response) <class 'google.generativeai.types.generation_types.GenerateContentResponse'>\n",
      "response response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"[{\\\"question\\\": \\\"A support vector machine (SVM) with a linear kernel is always more efficient than an SVM with a polynomial kernel.\\\", \\\"answer\\\": \\\"false\\\"}, {\\\"question\\\": \\\"In a decision tree, the information gain is calculated using the entropy of the parent node and the entropy of the child nodes.\\\", \\\"answer\\\": \\\"true\\\"}, {\\\"question\\\": \\\"A neural network with a single hidden layer can approximate any continuous function.\\\", \\\"answer\\\": \\\"true\\\"}, {\\\"question\\\": \\\"Cross-validation is a technique used to estimate the performance of a machine learning model on unseen data.\\\", \\\"answer\\\": \\\"true\\\"}, {\\\"question\\\": \\\"The bias-variance trade-off is a fundamental concept in machine learning that states that increasing bias will always decrease variance.\\\", \\\"answer\\\": \\\"false\\\"}, {\\\"question\\\": \\\"Unsupervised learning algorithms require labeled data to train.\\\", \\\"answer\\\": \\\"false\\\"}, {\\\"question\\\": \\\"The k-nearest neighbors algorithm is a supervised learning algorithm.\\\", \\\"answer\\\": \\\"true\\\"}, {\\\"question\\\": \\\"The gradient descent algorithm always converges to the global minimum of a cost function.\\\", \\\"answer\\\": \\\"false\\\"}, {\\\"question\\\": \\\"Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function.\\\", \\\"answer\\\": \\\"true\\\"}, {\\\"question\\\": \\\"The accuracy of a machine learning model is always the best metric for evaluating its performance.\\\", \\\"answer\\\": \\\"false\\\"}]\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 376,\n",
      "        \"candidates_token_count\": 283,\n",
      "        \"total_token_count\": 659\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "prompt_question_generator.format( \n",
    "    additional_task_description=parameters[\"additional_task_description\"],\n",
    "    quantity=parameters[\"level\"],\n",
    "    level=parameters[\"level\"],\n",
    "    domain_knowledge=domain_knowledge,\n",
    "    object_schema=object_schema  )\n",
    "\n",
    "response = llm_gemini.generate_content(prompt_question_generator)\n",
    "\n",
    "print(\"type(response)\", type(response))\n",
    "\n",
    "print( \"response\", response )\n",
    "\n",
    "# questions = json_parser(response)\n",
    "\n",
    "# for q in questions:\n",
    "#     print(\"-----------------------questions-----------------------\")\n",
    "#     print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------questions-----------------------\n",
      "{'question': 'A support vector machine (SVM) with a linear kernel is always more efficient than an SVM with a polynomial kernel.', 'answer': 'false'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'In a decision tree, the information gain is calculated using the entropy of the parent node and the entropy of the child nodes.', 'answer': 'true'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'A neural network with a single hidden layer can approximate any continuous function.', 'answer': 'true'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'Cross-validation is a technique used to estimate the performance of a machine learning model on unseen data.', 'answer': 'true'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'The bias-variance trade-off is a fundamental concept in machine learning that states that increasing bias will always decrease variance.', 'answer': 'false'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'Unsupervised learning algorithms require labeled data to train.', 'answer': 'false'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'The k-nearest neighbors algorithm is a supervised learning algorithm.', 'answer': 'true'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'The gradient descent algorithm always converges to the global minimum of a cost function.', 'answer': 'false'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function.', 'answer': 'true'}\n",
      "-----------------------questions-----------------------\n",
      "{'question': 'The accuracy of a machine learning model is always the best metric for evaluating its performance.', 'answer': 'false'}\n"
     ]
    }
   ],
   "source": [
    "questions = json_parser(response.text)\n",
    "\n",
    "for q in questions:\n",
    "    print(\"-----------------------questions-----------------------\")\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
