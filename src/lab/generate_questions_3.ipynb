{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector database\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# ingestion\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# chat\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "import re\n",
    "\n",
    "# system\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# import nest_asyncio\n",
    "\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,  # Define o nível de log\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Define o formato da mensagem de log\n",
    "                    stream=sys.stdout)  # Define a saída do log para stdout\n",
    "                    # filename='app.log',  # Define o arquivo onde os logs serão gravados\n",
    "                    # filemode='a')  # Define o modo de escrita do arquivo de log (append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 14:02:37,559 - INFO - Inicializando LLM e embedings\n",
      "2024-08-12 14:02:37,588 - DEBUG - Using AsyncIOEngine.POLLER as I/O engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723471357.583539     685 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    }
   ],
   "source": [
    "logging.info('Inicializando LLM e embedings')\n",
    "llm_google = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", convert_system_message_to_human=True)\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm_openai = ChatOpenAI(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_schema = \"\"\"\n",
    "{\n",
    "  \"properties\": {\n",
    "    \"topic_description\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\n",
    "    },\n",
    "    \"level\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The difficulty level of the question. It should be only one of the following options: 'easy', 'medium', 'hard'.\"\n",
    "    },\n",
    "    \"question\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\n",
    "    },\n",
    "    \"answer\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"An explanation or solution to the question.\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"topic_description\", \"level\", \"question\", \"answer\", \"explanation\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question_generator = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "                TASK CONTEXT:\n",
    "                I am studying machine learning and I need to practice some questions on various topics.\n",
    "                \n",
    "                TASK DESCRIPTION:\n",
    "                I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\n",
    "                These questions should be interesting, creative, challenging and thought-provoking. \n",
    "                Each question should be in the form of a statement that could be either TRUE or FALSE.\n",
    "                Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\n",
    "                I will provide the topics in the DOMAIN KNOWLEDGE section.\n",
    "                The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\n",
    "                \n",
    "                ADDITIONAL TASK DESCRIPTION:\n",
    "                {additional_task_description}\n",
    "                \n",
    "                TASK REQUIREMENTS:\n",
    "                Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\n",
    "                You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\n",
    "                Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\n",
    "                \n",
    "                TASK DETAILS:\n",
    "                You should create {quantity} questions of level {level}.\n",
    "                \n",
    "                DOMAIN KNOWLEDGE:\n",
    "                {domain_knowledge}\n",
    "                \n",
    "                FORMAT OUTPUT INSTRUCTIONS:\n",
    "                The output should be formatted as a JSON list of objects that conforms class object schema below.\n",
    "                You should output just the Json list. \n",
    "                You should not output any other word like \"json\" in the beginning because it will ruin the parser.\n",
    "\n",
    "                ```\n",
    "                {object_schema}\n",
    "                ```\n",
    "            \"\"\",\n",
    "    input_variables=[\"quantity\", \"level\", \"additional_task_description\"],\n",
    "    partial_variables={\"object_schema\": object_schema},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 14:02:56,509 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-08-12 14:02:56,512 - DEBUG - load_verify_locations cafile='/workspaces/llm-quiz-creator-streamlitapp-trainer/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from typing import List, Optional\n",
    "import  json_repair\n",
    "\n",
    "def json_parser(message: AIMessage) -> List[dict]:\n",
    "    return json_repair.loads(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(text, llm, parameters, subject_matter_1, subject_matter_2):\n",
    "    print( \"------------------- generate_questions FUNCTION -------------------\" )\n",
    "    \n",
    "    if text is None:\n",
    "        raise Exception(\"text is None\")\n",
    "        \n",
    "    try:\n",
    "        chain = prompt_question_generator | llm\n",
    "        \n",
    "        parameters[\"domain_knowledge\"] = text\n",
    "        \n",
    "        response = chain.invoke(parameters)\n",
    "        \n",
    "        questions = json_parser(response)\n",
    "        \n",
    "        for q in questions:\n",
    "            q[\"subject_matter_1\"] = subject_matter_1\n",
    "            q[\"subject_matter_2\"] = subject_matter_2    \n",
    "\n",
    "        print(\"---------------------------questions---------------------------\")\n",
    "        print(questions)\n",
    "        print(\"---------------------------questions---------------------------\")\n",
    "        \n",
    "        # data, count = supabase.table('questions').insert(questions).execute()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Questions about the correct shape of the layers in Neural network implementation in Pytorch. \n",
    "We know that when we are creating neural networks we need to know the if the shapes are correct aligned. SO I want to test this.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Create Pytorch code of a neural network implementation and ask if the shape of the layer is correct.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Create Pytorch code of a neural network implementation and ask if the shape of the layer is correct.\n",
    "Generate just the pytorch code. Dont start with 'The following PyTorch code defines a neural network with ....'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: beginner\n",
      "------------------- generate_questions FUNCTION -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-quiz-creator-streamlitapp-trainer/.venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------questions---------------------------\n",
      "[{'topic_description': 'PyTorch neural network layer shape', 'level': 'beginner', 'question': 'The following PyTorch code defines a neural network with a hidden layer of shape (10, 5) and an output layer of shape (5, 1). The shape of the hidden layer is correctly defined according to the input and output dimensions.\\n\\n```python\\nimport torch.nn as nn\\n\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.fc1 = nn.Linear(10, 5)  # Hidden layer\\n        self.fc2 = nn.Linear(5, 1)  # Output layer\\n\\n    def forward(self, x):\\n        x = self.fc1(x)\\n        x = self.fc2(x)\\n        return x\\n```', 'answer': 'TRUE', 'explanation': 'The code defines a neural network with a hidden layer of shape (10, 5), which means it has 10 input features and 5 output neurons. This is consistent with the input and output dimensions of the layers. The output layer has a shape of (5, 1), meaning it takes 5 inputs from the hidden layer and produces a single output.', 'subject_matter_1': 'Probability - LLMs', 'subject_matter_2': 'Probability - LLMs'}]\n",
      "---------------------------questions---------------------------\n",
      "level: intermediate\n",
      "------------------- generate_questions FUNCTION -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-quiz-creator-streamlitapp-trainer/.venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------questions---------------------------\n",
      "[{'topic_description': 'PyTorch neural network layer shape', 'level': 'intermediate', 'question': 'The following PyTorch code defines a neural network with a hidden layer of shape (10, 5) and an output layer of shape (5, 1). The shape of the hidden layer is correct, considering the input is a batch of 10 samples with 5 features each.', 'answer': 'FALSE', 'explanation': 'The shape of the hidden layer is incorrect. The first dimension of the hidden layer should match the number of features in the input, which is 5. The second dimension should match the number of neurons in the hidden layer, which is 10. Therefore, the correct shape for the hidden layer is (5, 10). The provided code defines a hidden layer with the shape (10, 5), which is incorrect. The output layer shape is correct, as it needs to match the number of neurons in the hidden layer (10) and the number of output classes (1). \\n\\n```python\\nimport torch.nn as nn\\n\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.fc1 = nn.Linear(5, 10)  # Correct shape for hidden layer\\n        self.fc2 = nn.Linear(10, 1)  # Correct shape for output layer\\n\\n    def forward(self, x):\\n        x = self.fc1(x)\\n        x = self.fc2(x)\\n        return x\\n```', 'subject_matter_1': 'Probability - LLMs', 'subject_matter_2': 'Probability - LLMs'}]\n",
      "---------------------------questions---------------------------\n",
      "level: hard\n",
      "------------------- generate_questions FUNCTION -------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-quiz-creator-streamlitapp-trainer/.venv/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------questions---------------------------\n",
      "[{'topic_description': 'Neural network implementation in PyTorch', 'level': 'hard', 'question': 'The following PyTorch code for a neural network with two hidden layers, each with 100 neurons, and an output layer with 10 neurons, will result in an output layer with a shape of (batch\\\\_size, 10) after processing an input of shape (batch\\\\_size, 50):\\\\n\\\\n```python\\\\nimport torch.nn as nn\\\\n\\\\nclass Net(nn.Module):\\\\n    def __init__(self):\\\\n        super(Net, self).__init__()\\\\n        self.fc1 = nn.Linear(50, 100)\\\\n        self.fc2 = nn.Linear(100, 100)\\\\n        self.fc3 = nn.Linear(100, 10)\\\\n\\\\n    def forward(self, x):\\\\n        x = torch.relu(self.fc1(x))\\\\n        x = torch.relu(self.fc2(x))\\\\n        x = self.fc3(x)\\\\n        return x\\\\n```', 'answer': 'TRUE', 'explanation': 'The code defines a neural network with two hidden layers of 100 neurons each and an output layer of 10 neurons. The input shape is (batch\\\\_size, 50). The first linear layer `fc1` transforms the input from (batch\\\\_size, 50) to (batch\\\\_size, 100). The second linear layer `fc2` keeps the shape at (batch\\\\_size, 100). Finally, the output layer `fc3` transforms the shape to (batch\\\\_size, 10). Therefore, the output layer will have a shape of (batch\\\\_size, 10) after processing an input of shape (batch\\\\_size, 50).', 'subject_matter_1': 'Probability - LLMs', 'subject_matter_2': 'Probability - LLMs'}]\n",
      "---------------------------questions---------------------------\n"
     ]
    }
   ],
   "source": [
    "for level in [\n",
    "    \"beginner\", \n",
    "    \"intermediate\", \n",
    "    \"hard\"\n",
    "    ]:\n",
    "    print( \"level:\", level )\n",
    "    \n",
    "    parameters = {\n",
    "        \"quantity\": 1,\n",
    "        \"level\": level,\n",
    "        \"additional_task_description\": \"Create questions only about the definitions of the concepts, like mixing the definition of one with another distribution, or mixing the use of one with the use of another. I need this to memorize this concepts.\"\n",
    "    }\n",
    "    \n",
    "    subject_matter_1 = \"Probability - LLMs\"\n",
    "    subject_matter_2 = subject_matter_1\n",
    "    \n",
    "    generate_questions(text, llm_google, parameters, subject_matter_1, subject_matter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
