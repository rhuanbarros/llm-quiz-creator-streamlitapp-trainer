{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()  # take environment variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Question(BaseModel):\n",
    "    \"\"\" A question about a domain of study.\"\"\"\n",
    "\n",
    "    topic_description: str = Field(\n",
    "        description=\"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\n",
    "    )\n",
    "    level: float = Field(\n",
    "        description=\"The difficulty level of the question. It should be only one of the following options: 'easy', 'medium', 'hard'.\"\n",
    "    )\n",
    "    question: str = Field(\n",
    "        description=\"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\n",
    "    )\n",
    "    answer_correct: str = Field(\n",
    "        description=\"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\n",
    "    )\n",
    "    explanation: str = Field(\n",
    "        description=\"An explanation or solution to the question.\"\n",
    "    )\n",
    "\n",
    "class QuestionList(BaseModel):\n",
    "    \"\"\"A list of Question class.\"\"\"\n",
    "\n",
    "    items: list[Question] = Field(\n",
    "        description=\"list of Question\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-quiz-creator-streamlitapp-trainer/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723753125.961714    3301 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm_google = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "llm_google_QuestionList = llm_google.with_structured_output(QuestionList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question_generator = PromptTemplate.from_template(\"\"\"\n",
    "\n",
    "    TASK CONTEXT:\n",
    "    I am studying machine learning and I need to practice some questions on various topics.\n",
    "    \n",
    "    TASK DESCRIPTION:\n",
    "    I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\n",
    "    These questions should be interesting, creative, challenging and thought-provoking. \n",
    "    Each question should be in the form of a statement that could be either TRUE or FALSE.\n",
    "    Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\n",
    "    I will provide the topics in the DOMAIN KNOWLEDGE section.\n",
    "    The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\n",
    "    \n",
    "    ADDITIONAL TASK DESCRIPTION:\n",
    "    {additional_task_description}\n",
    "    \n",
    "    TASK REQUIREMENTS:\n",
    "    Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\n",
    "    You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\n",
    "    Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\n",
    "    \n",
    "    TASK DETAILS:\n",
    "    You should create {quantity} questions of level {level}.\n",
    "    \n",
    "    DOMAIN KNOWLEDGE:\n",
    "    {domain_knowledge}\n",
    "    \n",
    "    FORMAT OUTPUT INSTRUCTIONS:\n",
    "    It should be formatted as described in the output format.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import AIMessage, HumanMessage\n",
    "# from typing import List, Optional\n",
    "# import  json_repair\n",
    "\n",
    "# def json_parser(message: AIMessage) -> List[dict]:\n",
    "#     return json_repair.loads(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "Language Models and Probability\n",
    "Entropy\n",
    "Cross-Entropy\n",
    "Cross-Entropy Loss\n",
    "Perplexity\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(text, llm, parameters, subject_matter_1, subject_matter_2):\n",
    "    print( \"------------------- generate_questions FUNCTION -------------------\" )\n",
    "    \n",
    "    if text is None:\n",
    "        raise Exception(\"text is None\")\n",
    "        \n",
    "    try:\n",
    "        chain = prompt_question_generator | llm\n",
    "        \n",
    "        parameters[\"domain_knowledge\"] = text\n",
    "        \n",
    "        questions = chain.invoke(parameters)\n",
    "        \n",
    "        # questions = json_parser(response)\n",
    "        \n",
    "        for q in questions:\n",
    "            q[\"subject_matter_1\"] = subject_matter_1\n",
    "            # q[\"subject_matter_2\"] = subject_matter_2    \n",
    "        \n",
    "            print(\"-----------------------questions-----------------------\")\n",
    "            print(q)\n",
    "            \n",
    "\n",
    "        # data, count = supabase.table('questions').insert(questions).execute()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: hard\n",
      "------------------- generate_questions FUNCTION -------------------\n",
      "An error occurred: Invalid argument provided to Gemini: 400 * GenerateContentRequest.tools[0].function_declarations[0].parameters.properties[items].items: missing field.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for level in [\n",
    "    # \"beginner\", \n",
    "    # \"intermediate\", \n",
    "    \"hard\"\n",
    "    ]:\n",
    "    print( \"level:\", level )\n",
    "    \n",
    "    parameters = {\n",
    "        \"quantity\": 1,\n",
    "        \"level\": level,\n",
    "        \"additional_task_description\": \"Create questions only about the definitions of the concepts, like mixing the definition of one with another distribution, or mixing the use of one with the use of another. I need this to memorize this concepts.\"\n",
    "    }\n",
    "    \n",
    "    subject_matter_1 = \"Probability - LLMs\"\n",
    "    subject_matter_2 = subject_matter_1\n",
    "    \n",
    "    generate_questions(text, llm_google_QuestionList, parameters, subject_matter_1, subject_matter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
