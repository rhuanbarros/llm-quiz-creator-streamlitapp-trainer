{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import json_repair\n",
    "import os\n",
    "\n",
    "key_groq = os.environ[\"GROQ_API_KEY\"]\n",
    "client = Groq(api_key=key_groq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_schema = \"\"\"\n",
    "  {\n",
    "    \"topic_description\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\n",
    "    },\n",
    "    \"level\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The difficulty level of the question. It should be only one of the following options: 'beginner', 'intermediate', 'advanced'.\"\n",
    "    },\n",
    "    \"question\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\n",
    "    },\n",
    "    \"answer_correct\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"An explanation or solution to the question.\"\n",
    "    }\n",
    "  }\n",
    "\"\"\"\n",
    "\n",
    "prompt_question_generator = \"\"\"\n",
    "              TASK CONTEXT:\n",
    "              I am studying machine learning and I need to practice some questions on various topics.\n",
    "              \n",
    "              TASK DESCRIPTION:\n",
    "              I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\n",
    "              These questions should be interesting, creative, challenging and thought-provoking. \n",
    "              Each question should be in the form of a statement that could be either TRUE or FALSE.\n",
    "              Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\n",
    "              I will provide the topics in the DOMAIN KNOWLEDGE section.\n",
    "              The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\n",
    "              \n",
    "              ADDITIONAL TASK DESCRIPTION:\n",
    "              {additional_task_description}\n",
    "              \n",
    "              TASK REQUIREMENTS:\n",
    "              Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\n",
    "              You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\n",
    "              Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\n",
    "              \n",
    "              TASK DETAILS:\n",
    "              You should create {quantity} questions of level {level}.\n",
    "              \n",
    "              DOMAIN KNOWLEDGE:\n",
    "              {domain_knowledge}\n",
    "              \n",
    "              FORMAT OUTPUT INSTRUCTIONS:\n",
    "              It should be formatted in list of JSON objects as described below.\n",
    "              {json_schema}\n",
    "          \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"domain_knowledge\": \"\"\"\n",
    "            Language Models and Probability\n",
    "            Entropy\n",
    "            Cross-Entropy\n",
    "            Cross-Entropy Loss\n",
    "            Perplexity\n",
    "        \"\"\",\n",
    "    \"additional_task_description\": \"Create questions only about the definitions of the concepts, like mixing the definition of one with another, or mixing the use of one with the use of another. I need this to memorize this concepts.\",\n",
    "    \"quantity\": \"1\",\n",
    "    \"level\": \"easy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question_generator_formatted = prompt_question_generator.format(\n",
    "        additional_task_description=parameters[\"additional_task_description\"],\n",
    "        quantity=parameters[\"quantity\"],\n",
    "        level=parameters[\"level\"],\n",
    "        domain_knowledge=parameters[\"domain_knowledge\"],\n",
    "        json_schema=json_schema,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt_question_generator_formatted}],\n",
    "    temperature=1,\n",
    "    max_tokens=2420,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "completion = response.choices[0].message\n",
    "questions = json_repair.loads(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_description': 'Measuring model uncertainty',\n",
       " 'level': 'easy',\n",
       " 'question': 'Perplexity is a measure of model entropy, and thus is inversely proportional to cross-entropy loss.',\n",
       " 'answer_correct': 'FALSE',\n",
       " 'explanation': 'Perplexity measures how well a model predicts a dataset, but it is not directly related to model entropy or cross-entropy loss.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_description': 'Measuring model uncertainty',\n",
       " 'level': 'easy',\n",
       " 'question': 'Perplexity is a measure of model entropy, and thus is inversely proportional to cross-entropy loss.',\n",
       " 'answer_correct': 'FALSE',\n",
       " 'explanation': 'Perplexity measures how well a model predicts a dataset, but it is not directly related to model entropy or cross-entropy loss.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isinstance(questions, list):\n",
    "    questions_ = [questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(questions_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic_description': 'Measuring model uncertainty', 'level': 'easy', 'question': 'Perplexity is a measure of model entropy, and thus is inversely proportional to cross-entropy loss.', 'answer_correct': 'FALSE', 'explanation': 'Perplexity measures how well a model predicts a dataset, but it is not directly related to model entropy or cross-entropy loss.'}\n"
     ]
    }
   ],
   "source": [
    "for question in questions_:\n",
    "    print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
