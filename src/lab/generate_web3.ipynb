{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# vector database\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "# ingestion\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# chat\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "import re\n",
    "\n",
    "# system\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,  # Define o nível de log\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Define o formato da mensagem de log\n",
    "                    stream=sys.stdout)  # Define a saída do log para stdout\n",
    "                    # filename='app.log',  # Define o arquivo onde os logs serão gravados\n",
    "                    # filemode='a')  # Define o modo de escrita do arquivo de log (append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"quiz\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b626f8e0970e43cca449e7a3510ac96b\"  # Update to your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 19:18:56,916 - INFO - Inicializando LLM e embedings\n"
     ]
    }
   ],
   "source": [
    "logging.info('Inicializando LLM e embedings')\n",
    "api_key_google = \"AIzaSyC-V6lfROehy46ntB6zPZ7CJ8zNF3gDdO4\"\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True, google_api_key=api_key_google)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=api_key_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 19:18:57,173 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-03-30 19:18:57,175 - DEBUG - load_verify_locations cafile='/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "2024-03-30 19:18:57,214 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-03-30 19:18:57,215 - DEBUG - load_verify_locations cafile='/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_openai = ChatOpenAI(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_schema = \"\"\"\n",
    "{\n",
    "  \"properties\": {\n",
    "    \"topic_description\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\n",
    "    },\n",
    "    \"level\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The difficulty level of the question. It should be only one of the following options: 'beginner', 'intermediate', 'advanced'.\"\n",
    "    },\n",
    "    \"question\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\n",
    "    },\n",
    "    \"answer\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"An explanation or solution to the question.\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"topic_description\", \"level\", \"question\", \"answer\", \"explanation\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_question_generator = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "                TASK CONTEXT:\n",
    "                I am studying machine learning and I need to practice some questions on various topics.\n",
    "                \n",
    "                TASK DESCRIPTION:\n",
    "                I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\n",
    "                These questions should be interesting, creative, challenging and thought-provoking. \n",
    "                Each question should be in the form of a statement that could be either TRUE or FALSE.\n",
    "                Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\n",
    "                I will provide the topics in the DOMAIN KNOWLEDGE section.\n",
    "                The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\n",
    "                \n",
    "                TASK REQUIREMENTS:\n",
    "                Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\n",
    "                You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\n",
    "                Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\n",
    "                \n",
    "                TASK DETAILS:\n",
    "                You should create {quantity} questions of level {level}.\n",
    "                \n",
    "                DOMAIN KNOWLEDGE:\n",
    "                {domain_knowledge}\n",
    "                \n",
    "                FORMAT OUTPUT INSTRUCTIONS:\n",
    "                The output should be formatted as a JSON list of objects that conforms class object schema below.\n",
    "                You should output just the Json list. \n",
    "                You should not output any other word like \"json\" in the beginning because it will ruin the parser.\n",
    "\n",
    "                ```\n",
    "                {object_schema}\n",
    "                ```\n",
    "            \"\"\",\n",
    "    input_variables=[\"quantity\", \"level\"],\n",
    "    partial_variables={\"object_schema\": object_schema},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-30 19:18:57,345 - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "2024-03-30 19:18:57,346 - DEBUG - load_verify_locations cafile='/home/rhuan/PROJETOS/quiz_proj2/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "url = \"https://xoxlgvakygiyfijfeixu.supabase.co\"\n",
    "key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhveGxndmFreWdpeWZpamZlaXh1Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcwNDkyNzU2NywiZXhwIjoyMDIwNTAzNTY3fQ.V3766GRj6hkt1Ci-52tjSiULVoF3nfCPPDnR6Hc_rT0\"\n",
    "\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  json_repair\n",
    "\n",
    "def json_parser(message: AIMessage) -> List[dict]:\n",
    "    return json_repair.loads(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h1(html_header_splits):\n",
    "    for html in html_header_splits:\n",
    "        if \"Header 1\" in html.metadata.keys():\n",
    "            return html.metadata[\"Header 1\"]\n",
    "            \n",
    "# get_h1(html_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_header(split):\n",
    "    if 'Header 3' in split.metadata.keys():\n",
    "        return split.metadata['Header 3']\n",
    "    elif 'Header 2' in split.metadata.keys():\n",
    "        return split.metadata['Header 2']\n",
    "    elif 'Header 1' in split.metadata.keys():\n",
    "        return split.metadata['Header 1']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# get_sub_header(char_splits[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "def get_splits(url):\n",
    "    headers_to_split_on = [\n",
    "        (\"h1\", \"Header 1\"),\n",
    "        (\"h2\", \"Header 2\"),\n",
    "        (\"h3\", \"Header 3\"),\n",
    "        (\"h4\", \"Header 4\"),\n",
    "        (\"h5\", \"Header 5\"),\n",
    "    ]\n",
    "\n",
    "    html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    html_header_splits = html_splitter.split_text_from_url(url)\n",
    "    \n",
    "    # print( html_header_splits)\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500, \n",
    "        chunk_overlap=100,\n",
    "        \n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(html_header_splits)\n",
    "    return splits, html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []\n",
    "question_list = []\n",
    "try_later_split_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(splits, llm, parameters, html_header_splits):\n",
    "    print( \"------------------- generate_questions FUNCTION -------------------\" )\n",
    "    \n",
    "    i = 0\n",
    "    for split in splits:\n",
    "        print( \"-------------------- split --------------------\" )\n",
    "        print( split )\n",
    "        print( \"-------------------- split --------------------\" )\n",
    "        \n",
    "        try:\n",
    "            chain = prompt_question_generator | llm\n",
    "            \n",
    "            parameters[\"domain_knowledge\"] = split.page_content\n",
    "            \n",
    "            response = chain.invoke(parameters)\n",
    "            \n",
    "            response_list.append(response)\n",
    "            \n",
    "            questions = json_parser(response)\n",
    "            \n",
    "            h1 = get_h1(html_header_splits)\n",
    "            \n",
    "            sub_header = get_sub_header(split)\n",
    "            if sub_header is None:\n",
    "                sub_header = h1\n",
    "            \n",
    "            for q in questions:\n",
    "                q[\"subject_matter_1\"] = h1\n",
    "                q[\"subject_matter_2\"] = sub_header\n",
    "            \n",
    "            question_list.extend(questions)\n",
    "            \n",
    "            data, count = supabase.table('questions').insert(questions).execute()\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "            try_later_split_list.append(split)\n",
    "        \n",
    "        # i +=1\n",
    "        # if i == 2:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "def extract_links_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # base_url = urlparse(url).scheme + '://' + urlparse(url).netloc\n",
    "            base_url = url\n",
    "            links = []\n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link.get('href')\n",
    "                if href.startswith('http'):\n",
    "                    links.append(href)\n",
    "                else:\n",
    "                    links.append(urljoin(base_url, href))\n",
    "            return links\n",
    "        else:\n",
    "            print(f\"Failed to retrieve page: {response.status_code}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(links):\n",
    "    i = len(links)-1\n",
    "    while i >= 0:\n",
    "        # print(links[i])\n",
    "        if links[i] == 'https://aman.ai':\n",
    "            links.pop(i)\n",
    "        elif links[i] == 'https://aman.ai/':\n",
    "            links.pop(i)\n",
    "        elif links[i] == 'https://aman.ai/primers/ai/ml-comp/':\n",
    "            links.pop(i)\n",
    "        elif links[i] == 'https://aman.ai/cs229/linear-regression/':\n",
    "            links.pop(i)\n",
    "        elif links[i].startswith(\"https://aman.ai\") == False:\n",
    "            links.pop(i)\n",
    "        i -= 1\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_urls = [\n",
    "    \"https://aman.ai/cs229/\",\n",
    "    \"https://aman.ai/cs230/\",\n",
    "    \"https://aman.ai/cs231n/\",\n",
    "    \"https://aman.ai/cs224n/\",\n",
    "    \"https://aman.ai/coursera-ml/\",\n",
    "    \"https://aman.ai/recsys/index.html\",\n",
    "    \"https://aman.ai/coursera-dl/\",\n",
    "    \"https://aman.ai/coursera-nlp/\",\n",
    "    \"https://aman.ai/multimodal/\",\n",
    "    \"https://aman.ai/primers/ai/\",\n",
    "    \"https://aman.ai/primers/graph/\",\n",
    "    \"https://aman.ai/primers/numpy/\",\n",
    "    \"https://aman.ai/primers/matplotlib/\",\n",
    "    \"https://aman.ai/primers/pandas/\",\n",
    "    \"https://aman.ai/primers/python/\",\n",
    "    \"https://aman.ai/primers/tensorflow/\",\n",
    "    \"https://aman.ai/primers/backprop/\",\n",
    "    \"https://aman.ai/primers/math/\",\n",
    "    \"https://aman.ai/code/\",\n",
    "    \"https://aman.ai/code/data-structures/\",\n",
    "    \"https://aman.ai/code/asymptotic-notations/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.disable(logging.DEBUG)\n",
    "\n",
    "# Re-enable debug logs\n",
    "logging.disable(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of main_urls 21\n",
      "\n",
      "main_urls # 0\n",
      "main url: https://aman.ai/cs229/\n",
      "2024-03-30 19:25:20,361 - DEBUG - Starting new HTTPS connection (1): aman.ai:443\n",
      "2024-03-30 19:25:20,564 - DEBUG - https://aman.ai:443 \"GET /cs229/ HTTP/1.1\" 200 25899\n",
      "\n",
      "Quantity of internal_links_cleaned 22\n",
      "\n",
      "internal link # 0\n",
      "internal link https://aman.ai/cs229/locally-weighted-linear-regression/\n",
      "2024-03-30 19:25:20,578 - DEBUG - Starting new HTTPS connection (1): aman.ai:443\n",
      "2024-03-30 19:25:20,789 - DEBUG - https://aman.ai:443 \"GET /cs229/locally-weighted-linear-regression/ HTTP/1.1\" 200 28568\n",
      "level: beginner\n",
      "\n",
      "Quantity of splits 17\n",
      "------------------- generate_questions FUNCTION -------------------\n",
      "-------------------- split --------------------\n",
      "page_content='CS229 • Locally Weighted Linear Regression Fitting your data Feature selection algorithms Locally weighted linear regression Bandwidth parameter Cost function intuition Applications Parametric vs. non-parametric learning Linear regression Locally weighted linear regression References Citation'\n",
      "-------------------- split --------------------\n",
      "2024-03-30 19:25:20,814 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '\\n                TASK CONTEXT:\\n                I am studying machine learning and I need to practice some questions on various topics.\\n                \\n                TASK DESCRIPTION:\\n                I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\\n                These questions should be interesting, creative, challenging and thought-provoking. \\n                Each question should be in the form of a statement that could be either TRUE or FALSE.\\n                Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\\n                I will provide the topics in the DOMAIN KNOWLEDGE section.\\n                The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\\n                \\n                TASK REQUIREMENTS:\\n                Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\\n                You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\\n                Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\\n                \\n                TASK DETAILS:\\n                You should create 5 questions of level beginner.\\n                \\n                DOMAIN KNOWLEDGE:\\n                CS229 • Locally Weighted Linear Regression Fitting your data Feature selection algorithms Locally weighted linear regression Bandwidth parameter Cost function intuition Applications Parametric vs. non-parametric learning Linear regression Locally weighted linear regression References Citation\\n                \\n                FORMAT OUTPUT INSTRUCTIONS:\\n                The output should be formatted as a JSON list of objects that conforms class object schema below.\\n                You should output just the Json list. \\n                You should not output any other word like \"json\" in the beginning because it will ruin the parser.\\n\\n                ```\\n                \\n{\\n  \"properties\": {\\n    \"topic_description\": {\\n      \"type\": \"string\",\\n      \"description\": \"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\\n    },\\n    \"level\": {\\n      \"type\": \"string\",\\n      \"description\": \"The difficulty level of the question. It should be only one of the following options: \\'beginner\\', \\'intermediate\\', \\'advanced\\'.\"\\n    },\\n    \"question\": {\\n      \"type\": \"string\",\\n      \"description\": \"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\\n    },\\n    \"answer\": {\\n      \"type\": \"string\",\\n      \"description\": \"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\\n    },\\n    \"explanation\": {\\n      \"type\": \"string\",\\n      \"description\": \"An explanation or solution to the question.\"\\n    }\\n  },\\n  \"required\": [\"topic_description\", \"level\", \"question\", \"answer\", \"explanation\"]\\n}\\n\\n                ```\\n            '}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "2024-03-30 19:25:20,815 - DEBUG - close.started\n",
      "2024-03-30 19:25:20,816 - DEBUG - close.complete\n",
      "2024-03-30 19:25:20,816 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "2024-03-30 19:25:20,852 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f089030ec50>\n",
      "2024-03-30 19:25:20,853 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f089c5d35c0> server_hostname='api.openai.com' timeout=None\n",
      "2024-03-30 19:25:20,867 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f088fcef640>\n",
      "2024-03-30 19:25:20,868 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:20,869 - DEBUG - send_request_headers.complete\n",
      "2024-03-30 19:25:20,869 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:20,870 - DEBUG - send_request_body.complete\n",
      "2024-03-30 19:25:20,870 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,123 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 30 Mar 2024 22:25:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-9ourkab8vgbtjjqbb1uhuhq6'), (b'openai-processing-ms', b'8553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'60000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'59118'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'882ms'), (b'x-request-id', b'req_e36a85e8475c5adafc6ceb9340cb4ab7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'86cb83da78ea4d0f-GRU'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-03-30 19:25:30,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-30 19:25:30,124 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,125 - DEBUG - receive_response_body.complete\n",
      "2024-03-30 19:25:30,125 - DEBUG - response_closed.started\n",
      "2024-03-30 19:25:30,125 - DEBUG - response_closed.complete\n",
      "2024-03-30 19:25:30,126 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions \"200 OK\"\n",
      "2024-03-30 19:25:30,130 - DEBUG - close.started\n",
      "2024-03-30 19:25:30,131 - DEBUG - close.complete\n",
      "2024-03-30 19:25:30,131 - DEBUG - connect_tcp.started host='xoxlgvakygiyfijfeixu.supabase.co' port=443 local_address=None timeout=5 socket_options=None\n",
      "2024-03-30 19:25:30,213 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f088f3981c0>\n",
      "2024-03-30 19:25:30,213 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f08903089c0> server_hostname='xoxlgvakygiyfijfeixu.supabase.co' timeout=5\n",
      "2024-03-30 19:25:30,234 - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f088fd37c70>\n",
      "2024-03-30 19:25:30,234 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,235 - DEBUG - send_request_headers.complete\n",
      "2024-03-30 19:25:30,236 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,236 - DEBUG - send_request_body.complete\n",
      "2024-03-30 19:25:30,237 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,666 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 201, b'Created', [(b'Date', b'Sat, 30 Mar 2024 22:25:30 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Range', b'*/*'), (b'CF-Ray', b'86cb84150bdc644b-GIG'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Strict-Transport-Security', b'max-age=2592000; includeSubDomains'), (b'content-profile', b'public'), (b'preference-applied', b'return=representation'), (b'sb-gateway-version', b'1'), (b'x-envoy-upstream-service-time', b'16'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "2024-03-30 19:25:30,667 - INFO - HTTP Request: POST https://xoxlgvakygiyfijfeixu.supabase.co/rest/v1/questions \"HTTP/1.1 201 Created\"\n",
      "2024-03-30 19:25:30,668 - DEBUG - receive_response_body.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,668 - DEBUG - receive_response_body.complete\n",
      "2024-03-30 19:25:30,669 - DEBUG - response_closed.started\n",
      "2024-03-30 19:25:30,669 - DEBUG - response_closed.complete\n",
      "-------------------- split --------------------\n",
      "page_content='Fitting your data Feature selection algorithms Locally weighted linear regression Parametric vs. non-parametric learning References Citation  \\nBandwidth parameter Cost function intuition Applications  \\nLinear regression Locally weighted linear regression' metadata={'Header 1': 'CS229 • Locally Weighted Linear Regression'}\n",
      "-------------------- split --------------------\n",
      "2024-03-30 19:25:30,680 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': '\\n                TASK CONTEXT:\\n                I am studying machine learning and I need to practice some questions on various topics.\\n                \\n                TASK DESCRIPTION:\\n                I will provide you with a list of topics, and I would like you to generate a list of TRUE or FALSE questions.\\n                These questions should be interesting, creative, challenging and thought-provoking. \\n                Each question should be in the form of a statement that could be either TRUE or FALSE.\\n                Feel free to be imaginative and attempt to confuse the student by blending related concepts or similar words.\\n                I will provide the topics in the DOMAIN KNOWLEDGE section.\\n                The questions should pertain to these topics, and you can use this knowledge as a foundation to create questions that delve deeper into the subject matter.\\n                \\n                TASK REQUIREMENTS:\\n                Please refrain from creating questions that require mathematical calculations, but you may create questions with mathematical formulas.\\n                You SHOULD use LATEX to write mathematical formulas and code, but you should use the Katex flavor.\\n                Also you should put $$ in the beggining of the katex code and $$ at the end of the code. This is necessary because the interpreter needs it.\\n                \\n                TASK DETAILS:\\n                You should create 5 questions of level beginner.\\n                \\n                DOMAIN KNOWLEDGE:\\n                Fitting your data Feature selection algorithms Locally weighted linear regression Parametric vs. non-parametric learning References Citation  \\nBandwidth parameter Cost function intuition Applications  \\nLinear regression Locally weighted linear regression\\n                \\n                FORMAT OUTPUT INSTRUCTIONS:\\n                The output should be formatted as a JSON list of objects that conforms class object schema below.\\n                You should output just the Json list. \\n                You should not output any other word like \"json\" in the beginning because it will ruin the parser.\\n\\n                ```\\n                \\n{\\n  \"properties\": {\\n    \"topic_description\": {\\n      \"type\": \"string\",\\n      \"description\": \"A sentence describing the sub-topic to which the question belongs. That means this sentence should specify in a granular level what specific sub-topic the question belongs to. It should be abstract in a way that other questions could be put in this description too. Use between 5 and 10 words.\"\\n    },\\n    \"level\": {\\n      \"type\": \"string\",\\n      \"description\": \"The difficulty level of the question. It should be only one of the following options: \\'beginner\\', \\'intermediate\\', \\'advanced\\'.\"\\n    },\\n    \"question\": {\\n      \"type\": \"string\",\\n      \"description\": \"The actual question text. It should be a question of type TRUE or FALSE. It means that the questions should be an assertion that could be answered with TRUE or FALSE.\"\\n    },\\n    \"answer\": {\\n      \"type\": \"string\",\\n      \"description\": \"The correct answer to the question. It should be only one of the following options: TRUE or FALSE\"\\n    },\\n    \"explanation\": {\\n      \"type\": \"string\",\\n      \"description\": \"An explanation or solution to the question.\"\\n    }\\n  },\\n  \"required\": [\"topic_description\", \"level\", \"question\", \"answer\", \"explanation\"]\\n}\\n\\n                ```\\n            '}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "2024-03-30 19:25:30,682 - DEBUG - send_request_headers.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,682 - DEBUG - send_request_headers.complete\n",
      "2024-03-30 19:25:30,683 - DEBUG - send_request_body.started request=<Request [b'POST']>\n",
      "2024-03-30 19:25:30,683 - DEBUG - send_request_body.complete\n",
      "2024-03-30 19:25:30,683 - DEBUG - receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    }
   ],
   "source": [
    "print( \"Quantity of main_urls\", len( main_urls ) )\n",
    "\n",
    "for i_main_urls, url in enumerate(main_urls):\n",
    "    print(\"\")\n",
    "    print( \"main_urls #\", i_main_urls )\n",
    "    print( \"main url:\", url )\n",
    "    \n",
    "    internal_links = extract_links_from_url(url)\n",
    "    internal_links_cleaned = clean_links(internal_links)\n",
    "    \n",
    "    print(\"\")\n",
    "    print( \"Quantity of internal_links_cleaned\", len( internal_links_cleaned ) )\n",
    "    \n",
    "    for i_internal_links_cleaned, link in enumerate(internal_links_cleaned):\n",
    "        print(\"\")\n",
    "        print( \"internal link #\", i_internal_links_cleaned )\n",
    "        print( \"internal link\", link )\n",
    "        \n",
    "        splits, html_header_splits = get_splits(link)\n",
    "        \n",
    "        for level in [\"beginner\", \"intermediate\", \"hard\"]:\n",
    "            print( \"level:\", level )\n",
    "            \n",
    "            parameters = {\n",
    "                \"quantity\": 5,\n",
    "                \"level\": level,\n",
    "            }\n",
    "            \n",
    "            print(\"\")\n",
    "            print( \"Quantity of splits\", len( splits ) )\n",
    "            \n",
    "            generate_questions(splits, llm_openai, parameters, html_header_splits)\n",
    "            print(\"passou\")\n",
    "            \n",
    "    #         break\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
